
@article{geyer1991,
	title = {Markov Chain Monte Carlo Maximum Likelihood},
	author = {Geyer, Charles J},
	year = {1991},
	date = {1991},
	journal = {Interface Proceedings.},
	langid = {en}
}



@InProceedings{Surjanovic2022Parallel,
  author = {Nikola Surjanovic and Saifuddin Syed and Alexandre Bouchard-C\^{o}t\'{e} and Trevor Campbell},
  title = {Parallel {T}empering {W}ith a {V}ariational {R}eference},
  booktitle = {Advances in Neural Information Processing Systems 36 (NeurIPS)},
  volume = {36},
  pages = {565--577},
  year = {2022}
}

@incollection{Bouchard2024MCMCdriven,
  author = {Alexandre Bouchard-C\^{o}t\'{e} and Trevor Campbell and Geoff Pleiss and Nikola Surjanovic},
  title = {M{C}{M}{C}-driven learning},
  booktitle = {Handbook of Markov Chain Monte Carlo},
  volume = {(Accepted)},
  year = {2024}
}



@article{cameron_recursive_2014,
	title = {Recursive {Pathways} to {Marginal} {Likelihood} {Estimation} with {Prior}-{Sensitivity} {Analysis}},
	volume = {29},
	issn = {0883-4237},
	url = {https://www.jstor.org/stable/43288518},
	abstract = {We investigate the utility to computational Bayesian analyses of a particular family of recursive marginal likelihood estimators characterized by the (equivalent) algorithms known as "biased sampling" or "reverse logistic regression" in the statistics literature and "the density of states" in physics. Through a pair of numerical examples (including mixture modeling of the well-known galaxy data set) we highlight the remarkable diversity of sampling schemes amenable to such recursive normalization, as well as the notable efficiency of the resulting pseudo-mixture distributions for gauging prior sensitivity in the Bayesian model selection context. Our key theoretical contributions are to introduce a novel heuristic (" thermodynamic integration via importance sampling") for qualifying the role of the bridging sequence in this procedure and to reveal various connections between these recursive estimators and the nested sampling technique.},
	number = {3},
	urldate = {2022-04-27},
	journal = {Statistical Science},
	author = {Cameron, Ewan and Pettitt, Anthony},
	year = {2014},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {397--419},
	annote = {
Section 4.1: Seems to be the only example of previous work using PT (called MC{\textasciicircum}3 here) with an ‘auxiliary’ reference distribution.
In this case that reference is not optimized, instead obtained analytically.
 
},
}



@article{geyer1995,
	title = {Annealing Markov Chain Monte Carlo with Applications to Ancestral Inference},
	author = {Geyer, Charles J. and Thompson, Elizabeth A.},
	year = {1995},
	date = {1995},
	journal = {Journal of the American Statistical Association},
	pages = {909--920},
	volume = {90},
	number = {431},
	doi = {10.2307/2291325},
	url = {https://www.jstor.org/stable/2291325},
	note = {Publisher: [American Statistical Association, Taylor & Francis, Ltd.]}
}

@InProceedings{Syed2021Parallel,
  author = {Saifuddin Syed and  Vittorio Romaniello and  Trevor Campbell and  Alexandre Bouchard-C\^{o}t\'{e}},
  title = {Parallel {T}empering on {O}ptimized {P}aths},
  booktitle = {International Conference on Machine Learning (ICML)},
  volume = {139},
  pages = {10033--10042},
  year = {2021}
}


@misc{syed_optimised_2024,
	title = {Optimised {Annealed} {Sequential} {Monte} {Carlo} {Samplers}},
	url = {http://arxiv.org/abs/2408.12057},
	doi = {10.48550/arXiv.2408.12057},
	abstract = {Annealed Sequential Monte Carlo (SMC) samplers are special cases of SMC samplers where the sequence of distributions can be embedded in a smooth path of distributions. Using this underlying path of distributions and a performance model based on the variance of the normalisation constant estimator, we systematically study dense schedule and large particle limits. From our theory and adaptive methods emerges a notion of global barrier capturing the inherent complexity of normalisation constant approximation under our performance model. We then turn the resulting approximations into surrogate objective functions of algorithm performance, and use them for methodology development. We obtain novel adaptive methodologies, Sequential SMC (SSMC) and Sequential AIS (SAIS) samplers, which address practical difficulties inherent in previous adaptive SMC methods. First, our SSMC algorithms are predictable: they produce a sequence of increasingly precise estimates at deterministic and known times. Second, SAIS, a special case of SSMC, enables schedule adaptation at a memory cost constant in the number of particles and require much less communication. Finally, these characteristics make SAIS highly efficient on GPUs. We develop an open-source, high-performance GPU implementation based on our methodology and demonstrate up to a hundred-fold speed improvement compared to state-of-the-art adaptive AIS methods.},
	urldate = {2025-09-18},
	publisher = {arXiv},
	author = {Syed, Saifuddin and Bouchard-Côté, Alexandre and Chern, Kevin and Doucet, Arnaud},
	month = aug,
	year = {2024},
	note = {arXiv:2408.12057 [stat]},
	keywords = {Statistics - Computation},
	annote = {Comment: 65 pages, 7 figures},
	file = {Preprint PDF:/Users/bouchard/Zotero/storage/92V79AC8/Syed et al. - 2024 - Optimised Annealed Sequential Monte Carlo Samplers.pdf:application/pdf;Snapshot:/Users/bouchard/Zotero/storage/KTMQMWWY/2408.html:text/html},
}



@article{neal2001,
	title = {Annealed importance sampling},
	author = {Neal, Radford M.},
	year = {2001},
	month = {04},
	date = {2001-04-01},
	journal = {Statistics and Computing},
	pages = {125--139},
	volume = {11},
	number = {2},
	doi = {10.1023/A:1008923215028},
	url = {https://doi.org/10.1023/A:1008923215028},
	langid = {en}
}

@article{delmoral2006,
	title = {Sequential Monte Carlo Samplers},
	author = {Del Moral, Pierre and Doucet, Arnaud and Jasra, Ajay},
	year = {2006},
	date = {2006},
	journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
	pages = {411--436},
	volume = {68},
	number = {3},
	url = {http://www.jstor.org/stable/3879283}
}

@article{okabe2001,
	title = {Replica-exchange Monte Carlo method for the isobaric{\textendash}isothermal ensemble},
	author = {Okabe, Tsuneyasu and Kawata, Masaaki and Okamoto, Yuko and Mikami, Masuhiro},
	year = {2001},
	month = {03},
	date = {2001-03},
	journal = {Chemical Physics Letters},
	pages = {435--439},
	volume = {335},
	number = {5-6},
	doi = {10.1016/S0009-2614(01)00055-0},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0009261401000550},
	langid = {en}
}

@article{syed2022,
	title = {Non-reversible parallel tempering: A scalable highly parallel MCMC scheme},
	author = {Syed, Saifuddin and {Bouchard-Côté}, Alexandre and Deligiannidis, George and Doucet, Arnaud},
	year = {2022},
	date = {2022},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	pages = {321--350},
	volume = {84},
	number = {2},
	doi = {10.1111/rssb.12464},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12464},
	note = {{\_}eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/rssb.12464},
	langid = {en}
}

@article{sakai2016,
	title = {Irreversible simulated tempering},
	author = {Sakai, Yuji and Hukushima, Koji},
	year = {2016},
	month = {10},
	date = {2016-10-15},
	journal = {Journal of the Physical Society of Japan},
	pages = {104002},
	volume = {85},
	number = {10},
	doi = {10.7566/JPSJ.85.104002},
	url = {http://arxiv.org/abs/1601.04286},
	note = {arXiv: 1601.04286}
}

@article{biron-lattes2024,
	title = {Automatic Regenerative Simulation via Non-Reversible Simulated Tempering},
	author = {Biron-Lattes, Miguel and Campbell, Trevor and {Bouchard-Côté}, Alexandre},
	year = {2024},
	date = {2024},
	journal = {Journal of the American Statistical Association},
	pages = {1-13},
	doi = {10.1080/01621459.2024.2335587},
	url = {https://doi.org/10.1080/01621459.2024.2335587},
	note = {Publisher: Taylor & Francis
{\_}eprint: https://doi.org/10.1080/01621459.2024.2335587}
}

@book{pleydell2021,
	title = {DRJP/nimbleAPT: v1.0.4},
	author = {Pleydell, David},
	year = {2021},
	month = {06},
	date = {2021-06-22},
	publisher = {Zenodo},
	doi = {10.5281/zenodo.5013688},
	url = {https://zenodo.org/records/5013688},
	note = {DOI: 10.5281/zenodo.5013688}
}




@misc{surjanovic_pigeonsjl_2023,
	title = {Pigeons.jl: {Distributed} {Sampling} {From} {Intractable} {Distributions}},
	shorttitle = {Pigeons.jl},
	url = {http://arxiv.org/abs/2308.09769},
	doi = {10.48550/arXiv.2308.09769},
	abstract = {We introduce a software package, Pigeons.jl, that provides a way to leverage distributed computation to obtain samples from complicated probability distributions, such as multimodal posteriors arising in Bayesian inference and high-dimensional distributions in statistical mechanics. Pigeons.jl provides simple APIs to perform such computations single-threaded, multi-threaded, and/or distributed over thousands of MPI-communicating machines. In addition, Pigeons.jl guarantees a property that we call strong parallelism invariance: the output for a given seed is identical irrespective of the number of threads and processes, which is crucial for scientific reproducibility and software validation. We describe the key features of Pigeons.jl and the approach taken to implement a distributed and randomized algorithm that satisfies strong parallelism invariance.},
	urldate = {2024-05-29},
	publisher = {arXiv},
	author = {Surjanovic, Nikola and Biron-Lattes, Miguel and Tiede, Paul and Syed, Saifuddin and Campbell, Trevor and Bouchard-Côté, Alexandre},
	month = aug,
	year = {2023},
	note = {arXiv:2308.09769 [cs, stat]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Statistics - Computation},
}



@ARTICLE{Bouchard2022Blang,
  author = {Alexandre Bouchard-C\^{o}t\'{e} and Kevin Chern and Davor Cubranic and Sahand Hosseini and Justin Hume and Matteo Lepur and Zihui Ouyang and Giorgio Sgarbi},
  title = {Blang: {P}robabilitistic {P}rogramming for {C}ombinatorial {S}paces},
  journal = {Journal of Statistical Software},
  volume = {103},
  pages = {1--98},
  year = {2022}
}

@inproceedings{ge2018,
	title = {International Conference on Artificial Intelligence and Statistics},
	author = {Ge, Hong and Xu, Kai and Ghahramani, Zoubin},
	year = {2018},
	month = {03},
	date = {2018-03-31},
	publisher = {PMLR},
	pages = {1682--1690},
	url = {https://proceedings.mlr.press/v84/ge18b.html},
	note = {ISSN: 2640-3498},
	langid = {en}
}

@article{bennett1976,
	title = {Efficient estimation of free energy differences from Monte Carlo data},
	author = {Bennett, Charles H},
	year = {1976},
	month = {10},
	date = {1976-10-01},
	journal = {Journal of Computational Physics},
	pages = {245--268},
	volume = {22},
	number = {2},
	doi = {10.1016/0021-9991(76)90078-4},
	url = {https://www.sciencedirect.com/science/article/pii/0021999176900784}
}

@article{xie2011,
	title = {Improving Marginal Likelihood Estimation for Bayesian Phylogenetic Model Selection},
	author = {Xie, Wangang and Lewis, Paul O. and Fan, Yu and Kuo, Lynn and Chen, Ming-Hui},
	year = {2011},
	month = {03},
	date = {2011-03-01},
	journal = {Systematic Biology},
	pages = {150--160},
	volume = {60},
	number = {2},
	doi = {10.1093/sysbio/syq085},
	url = {https://academic.oup.com/sysbio/article/60/2/150/2461669/Improving-Marginal-Likelihood-Estimation-for}
}

@article{gelman1998,
	title = {Simulating normalizing constants: from importance sampling to bridge sampling to path sampling},
	author = {Gelman, Andrew and Meng, Xiao-Li},
	year = {1998},
	month = {05},
	date = {1998-05},
	journal = {Statistical Science},
	pages = {163--185},
	volume = {13},
	number = {2},
	doi = {10.1214/ss/1028905934},
	url = {https://projecteuclid.org/euclid.ss/1028905934},
	note = {MR: MR1647507
Zbl: 0966.65004},
	langid = {en}
}

@article{miasojedow2013,
	title = {An Adaptive Parallel Tempering Algorithm},
	author = {Miasojedow, {B{\l}a{\.{z}}ej} and Moulines, Eric and Vihola, Matti},
	year = {2013},
	month = {07},
	date = {2013-07-01},
	journal = {Journal of Computational and Graphical Statistics},
	pages = {649--664},
	volume = {22},
	number = {3},
	doi = {10.1080/10618600.2013.778779},
	url = {https://doi.org/10.1080/10618600.2013.778779}
}

@article{atchadé2011,
	title = {Towards optimal scaling of metropolis-coupled Markov chain Monte Carlo},
	author = {{Atchadé}, Yves F. and Roberts, Gareth O. and Rosenthal, Jeffrey S.},
	year = {2011},
	month = {10},
	date = {2011-10-01},
	journal = {Statistics and Computing},
	pages = {555--568},
	volume = {21},
	number = {4},
	doi = {10.1007/s11222-010-9192-1},
	url = {https://link.springer.com/article/10.1007/s11222-010-9192-1},
	langid = {en}
}

@inbook{grosse2013,
	title = {Annealing between distributions by averaging moments},
	author = {Grosse, Roger B and Maddison, Chris J and Salakhutdinov, Russ R},
	editor = {Burges, C. J. C. and Bottou, L. and Welling, M. and Ghahramani, Z. and Weinberger, K. Q.},
	year = {2013},
	date = {2013},
	pages = {2769-2777},
	url = {http://papers.nips.cc/paper/4879-annealing-between-distributions-by-averaging-moments.pdf}
}


@inproceedings{brekelmans2020,
	title = {All in the {Exponential} {Family}: {Bregman} {Duality} in {Thermodynamic} {Variational} {Inference}},
	shorttitle = {All in the {Exponential} {Family}},
	url = {https://proceedings.mlr.press/v119/brekelmans20a.html},
	abstract = {The recently proposed Thermodynamic Variational Objective (TVO) leverages thermodynamic integration to provide a family of variational inference objectives, which both tighten and generalize the ubiquitous Evidence Lower Bound (ELBO). However, the tightness of TVO bounds was not previously known, an expensive grid search was used to choose a “schedule” of intermediate distributions, and model learning suffered with ostensibly tighter bounds. In this work, we propose an exponential family interpretation of the geometric mixture curve underlying the TVO and various path sampling methods, which allows us to characterize the gap in TVO likelihood bounds as a sum of KL divergences. We propose to choose intermediate distributions using equal spacing in the moment parameters of our exponential family, which matches grid search performance and allows the schedule to adaptively update over the course of training. Finally, we derive a doubly reparameterized gradient estimator which improves model learning and allows the TVO to benefit from more refined bounds. To further contextualize our contributions, we provide a unified framework for understanding thermodynamic integration and the TVO using Taylor series remainders.},
	language = {en},
	urldate = {2024-05-29},
	booktitle = {Proceedings of the 37th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Brekelmans, Rob and Masrani, Vaden and Wood, Frank and Steeg, Greg Ver and Galstyan, Aram},
	month = nov,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {1111--1122},
	file = {Full Text PDF:/Users/bouchard/Zotero/storage/X3HPIMXJ/Brekelmans et al. - 2020 - All in the Exponential Family Bregman Duality in .pdf:application/pdf;Supplementary PDF:/Users/bouchard/Zotero/storage/8ME89QAT/Brekelmans et al. - 2020 - All in the Exponential Family Bregman Duality in .pdf:application/pdf},
}


@article{lefebvre2009,
	title = {Path Sampling to Compute Integrated Likelihoods: An Adaptive Approach},
	author = {Lefebvre, {Geneviève} and Steele, Russell and Vandal, Alain C. and Narayanan, Sridar and Arnold, Douglas L.},
	year = {2009},
	month = {01},
	date = {2009-01-01},
	journal = {Journal of Computational and Graphical Statistics},
	pages = {415--437},
	volume = {18},
	number = {2},
	doi = {10.1198/jcgs.2009.07019},
	url = {https://doi.org/10.1198/jcgs.2009.07019},
	note = {Publisher: Taylor & Francis
{\_}eprint: https://doi.org/10.1198/jcgs.2009.07019}
}

@article{wang2022,
	title = {Warp Bridge Sampling: The Next Generation},
	author = {Wang, Lazhi and Jones, David E. and Meng, Xiao-Li},
	year = {2022},
	month = {04},
	date = {2022-04-03},
	journal = {Journal of the American Statistical Association},
	pages = {835--851},
	volume = {117},
	number = {538},
	doi = {10.1080/01621459.2020.1825447},
	url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1825447},
	langid = {en}
}

@article{paquet2009,
	title = {Perturbation Corrections in Approximate Inference: Mixture Modelling Applications},
	author = {Paquet, Ulrich and Winther, Ole and Opper, Manfred},
	year = {2009},
	date = {2009},
	journal = {Journal of Machine Learning Research},
	pages = {1263--1304},
	volume = {10},
	number = {43},
	url = {http://jmlr.org/papers/v10/paquet09a.html}
}

@article{donnet,
	title = {Using deterministic approximations to accelerate SMC for posterior sampling},
	author = {Donnet, Sophie and Robin, {Stéphane}},
	doi = {10.48550/arXiv.1707.07971}
}

@article{metropolis1953,
	title = {Equation of State Calculations by Fast Computing Machines},
	author = {Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward},
	year = {1953},
	month = {06},
	date = {1953-06-01},
	journal = {The Journal of Chemical Physics},
	pages = {1087--1092},
	volume = {21},
	number = {6},
	doi = {10.1063/1.1699114},
	url = {https://pubs.aip.org/jcp/article/21/6/1087/202680/Equation-of-State-Calculations-by-Fast-Computing},
	langid = {en}
}

@article{pincus1970,
	title = {A Monte Carlo Method for the Approximate Solution of Certain Types of Constrained Optimization Problems},
	author = {Pincus, Martin},
	year = {1970},
	date = {1970},
	journal = {Operations Research},
	pages = {1225--1228},
	volume = {18},
	number = {6},
	url = {https://www.jstor.org/stable/169420},
	note = {Publisher: INFORMS}
}

@article{andrieu2008,
	title = {A tutorial on adaptive MCMC},
	author = {Andrieu, Christophe and Thoms, Johannes},
	year = {2008},
	month = {12},
	date = {2008-12},
	journal = {Statistics and Computing},
	pages = {343--373},
	volume = {18},
	number = {4},
	doi = {10.1007/s11222-008-9110-y},
	url = {http://link.springer.com/10.1007/s11222-008-9110-y},
	langid = {en}
}

@article{chimisov2018,
	title = {Adapting The Gibbs Sampler},
	author = {Chimisov, Cyril and Latuszynski, Krzysztof and Roberts, Gareth},
	year = {2018},
	month = {01},
	date = {2018-01-28},
	journal = {arXiv:1801.09299 [stat]},
	url = {http://arxiv.org/abs/1801.09299},
	note = {arXiv: 1801.09299}
}
